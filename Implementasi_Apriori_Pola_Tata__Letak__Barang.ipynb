{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angelitaanap/Data_Mining/blob/main/Implementasi_Apriori_Pola_Tata__Letak__Barang.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICzlnwslhsMP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Read data\n",
        "df = pd.read_csv(\"/content/lala.csv\")\n",
        "\n",
        "# Drop 'ID Transaksi' column\n",
        "data = df.drop(['ID Transaksi'], axis=1)\n",
        "\n",
        "# Remove spaces after commas\n",
        "data = data.replace(', ', ',', regex=True)\n",
        "\n",
        "data = data.replace(' ', '', regex=True)\n",
        "\n",
        "# Remove double quotes\n",
        "data = data.replace('\"', '', regex=True)\n",
        "\n",
        "# Convert to lowercase\n",
        "data = data.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
        "\n",
        "# Save the cleaned data to a new CSV file\n",
        "data.to_csv('bersih.csv', index=False, header=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "2aiBg8JancbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "def list_unique_words(csv_path):\n",
        "    words = []\n",
        "    with open(csv_path, 'r') as file:\n",
        "        for line in file:\n",
        "            line_words = line.strip().split(',')\n",
        "            line_words = [word.replace('\"', '') for word in line_words]\n",
        "            words.extend(line_words)\n",
        "\n",
        "    unique_words = sorted(list(set(words)))  # Sort the unique words alphabetically\n",
        "    return unique_words\n",
        "\n",
        "csv_path = 'bersih.csv'\n",
        "unique_word_list = list_unique_words(csv_path)\n",
        "print(unique_word_list)\n",
        "\n",
        "# Read the CSV file without a header and name the column 'teks'\n",
        "df = pd.read_csv('bersih.csv', header=None, names=['teks'])\n",
        "\n",
        "vectorizer = CountVectorizer(vocabulary=unique_word_list)  # Set the vocabulary to unique_word_list\n",
        "X = vectorizer.fit_transform(df['teks'])\n",
        "count_df = pd.DataFrame(X.toarray(), columns=unique_word_list)\n",
        "\n",
        "# Display the result\n",
        "print(count_df)\n",
        "count_df.to_csv('binaryform.csv')\n",
        "\n",
        "support_values = {}\n",
        "target_words = unique_word_list\n",
        "\n",
        "for word in target_words:\n",
        "    #print(word)\n",
        "    support = count_df[word].sum() / len(count_df)\n",
        "    support_values[word] = support\n",
        "\n",
        "# Print the support values\n",
        "for word, support in support_values.items():\n",
        "    print(\"Support for\", word + \":\", support)\n",
        "\n",
        "frequent_itemsets = apriori(count_df, min_support=0.001, use_colnames=True)\n",
        "print(frequent_itemsets)\n",
        "\n",
        "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
        "rules[\"support\"] = rules[\"support\"] * len(df)  # Convert support from relative to absolute values\n",
        "\n",
        "print(rules)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTsCYPlTi5H3",
        "outputId": "6d09e720-8043-40b0-fbc9-3fa823f8ea2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mieinstan', 'minumanringan', 'sabun', 'sembako', 'snack', 'tisu']\n",
            "     mieinstan  minumanringan  sabun  sembako  snack  tisu\n",
            "0            0              0      1        0      0     0\n",
            "1            0              0      0        0      1     0\n",
            "2            0              1      0        0      1     0\n",
            "3            1              1      1        0      0     0\n",
            "4            0              1      0        0      1     0\n",
            "..         ...            ...    ...      ...    ...   ...\n",
            "295          0              1      0        0      0     0\n",
            "296          0              1      1        0      1     1\n",
            "297          0              0      0        0      1     1\n",
            "298          1              0      0        1      1     0\n",
            "299          1              0      1        1      0     0\n",
            "\n",
            "[300 rows x 6 columns]\n",
            "Support for mieinstan: 0.44\n",
            "Support for minumanringan: 0.3566666666666667\n",
            "Support for sabun: 0.42333333333333334\n",
            "Support for sembako: 0.38333333333333336\n",
            "Support for snack: 0.41333333333333333\n",
            "Support for tisu: 0.41\n",
            "     support                                    itemsets\n",
            "0   0.440000                                 (mieinstan)\n",
            "1   0.356667                             (minumanringan)\n",
            "2   0.423333                                     (sabun)\n",
            "3   0.383333                                   (sembako)\n",
            "4   0.413333                                     (snack)\n",
            "5   0.410000                                      (tisu)\n",
            "6   0.146667                  (minumanringan, mieinstan)\n",
            "7   0.176667                          (sabun, mieinstan)\n",
            "8   0.186667                        (sembako, mieinstan)\n",
            "9   0.180000                          (mieinstan, snack)\n",
            "10  0.156667                           (mieinstan, tisu)\n",
            "11  0.133333                      (sabun, minumanringan)\n",
            "12  0.123333                    (sembako, minumanringan)\n",
            "13  0.136667                      (minumanringan, snack)\n",
            "14  0.130000                       (minumanringan, tisu)\n",
            "15  0.153333                            (sabun, sembako)\n",
            "16  0.170000                              (sabun, snack)\n",
            "17  0.170000                               (sabun, tisu)\n",
            "18  0.170000                            (sembako, snack)\n",
            "19  0.150000                             (sembako, tisu)\n",
            "20  0.130000                               (tisu, snack)\n",
            "21  0.056667           (sabun, minumanringan, mieinstan)\n",
            "22  0.060000         (sembako, minumanringan, mieinstan)\n",
            "23  0.050000           (minumanringan, mieinstan, snack)\n",
            "24  0.053333            (minumanringan, mieinstan, tisu)\n",
            "25  0.063333                 (sabun, sembako, mieinstan)\n",
            "26  0.063333                   (sabun, mieinstan, snack)\n",
            "27  0.050000                    (sabun, mieinstan, tisu)\n",
            "28  0.093333                 (sembako, mieinstan, snack)\n",
            "29  0.053333                  (sembako, mieinstan, tisu)\n",
            "30  0.046667                    (tisu, mieinstan, snack)\n",
            "31  0.033333             (sabun, sembako, minumanringan)\n",
            "32  0.053333               (sabun, minumanringan, snack)\n",
            "33  0.053333                (sabun, minumanringan, tisu)\n",
            "34  0.043333             (sembako, minumanringan, snack)\n",
            "35  0.046667              (sembako, minumanringan, tisu)\n",
            "36  0.046667                (tisu, minumanringan, snack)\n",
            "37  0.063333                     (sabun, sembako, snack)\n",
            "38  0.063333                      (sabun, sembako, tisu)\n",
            "39  0.050000                        (sabun, tisu, snack)\n",
            "40  0.046667                      (sembako, tisu, snack)\n",
            "41  0.006667  (sabun, sembako, minumanringan, mieinstan)\n",
            "42  0.016667    (sabun, minumanringan, mieinstan, snack)\n",
            "43  0.020000     (sabun, minumanringan, mieinstan, tisu)\n",
            "44  0.020000  (sembako, minumanringan, mieinstan, snack)\n",
            "45  0.016667   (sembako, minumanringan, mieinstan, tisu)\n",
            "46  0.006667     (tisu, minumanringan, mieinstan, snack)\n",
            "47  0.023333          (sabun, sembako, mieinstan, snack)\n",
            "48  0.013333           (sabun, sembako, mieinstan, tisu)\n",
            "49  0.003333             (sabun, tisu, mieinstan, snack)\n",
            "50  0.016667           (sembako, tisu, mieinstan, snack)\n",
            "51  0.006667      (sabun, sembako, minumanringan, snack)\n",
            "52  0.010000       (sabun, sembako, minumanringan, tisu)\n",
            "53  0.016667         (sabun, tisu, minumanringan, snack)\n",
            "54  0.013333       (sembako, tisu, minumanringan, snack)\n",
            "55  0.013333               (sabun, tisu, sembako, snack)\n",
            "                 antecedents       consequents  antecedent support  \\\n",
            "0            (minumanringan)       (mieinstan)            0.356667   \n",
            "1                (mieinstan)   (minumanringan)            0.440000   \n",
            "2                    (sabun)       (mieinstan)            0.423333   \n",
            "3                (mieinstan)           (sabun)            0.440000   \n",
            "4                  (sembako)       (mieinstan)            0.383333   \n",
            "..                       ...               ...                 ...   \n",
            "235   (sabun, sembako, tisu)           (snack)            0.063333   \n",
            "236     (sabun, snack, tisu)         (sembako)            0.050000   \n",
            "237  (sabun, sembako, snack)            (tisu)            0.063333   \n",
            "238   (sembako, snack, tisu)           (sabun)            0.046667   \n",
            "239            (snack, tisu)  (sabun, sembako)            0.130000   \n",
            "\n",
            "     consequent support  support  confidence      lift  leverage  conviction  \\\n",
            "0              0.440000     44.0    0.411215  0.934579 -0.010267    0.951111   \n",
            "1              0.356667     44.0    0.333333  0.934579 -0.010267    0.965000   \n",
            "2              0.440000     53.0    0.417323  0.948461 -0.009600    0.961081   \n",
            "3              0.423333     53.0    0.401515  0.948461 -0.009600    0.963544   \n",
            "4              0.440000     56.0    0.486957  1.106719  0.018000    1.091525   \n",
            "..                  ...      ...         ...       ...       ...         ...   \n",
            "235            0.413333      4.0    0.210526  0.509338 -0.012844    0.743111   \n",
            "236            0.383333      4.0    0.266667  0.695652 -0.005833    0.840909   \n",
            "237            0.410000      4.0    0.210526  0.513479 -0.012633    0.747333   \n",
            "238            0.423333      4.0    0.285714  0.674916 -0.006422    0.807333   \n",
            "239            0.153333      4.0    0.102564  0.668896 -0.006600    0.943429   \n",
            "\n",
            "     zhangs_metric  \n",
            "0        -0.098131  \n",
            "1        -0.111111  \n",
            "2        -0.086116  \n",
            "3        -0.088452  \n",
            "4         0.156371  \n",
            "..             ...  \n",
            "235      -0.507018  \n",
            "236      -0.315315  \n",
            "237      -0.502875  \n",
            "238      -0.335656  \n",
            "239      -0.362637  \n",
            "\n",
            "[240 rows x 10 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vJqQaj73iuOb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}